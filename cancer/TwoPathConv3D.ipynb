{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoPathConv (\n",
      "  (local_conv1): Conv3d(4, 64, kernel_size=(7, 7, 3), stride=(1, 1, 1))\n",
      "  (local_conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (local_conv3): Conv3d(4, 160, kernel_size=(13, 13, 5), stride=(1, 1, 1))\n",
      "  (total_conv): Conv3d(224, 5, kernel_size=(21, 21, 1), stride=(1, 1, 1))\n",
      ")\n",
      "Variable containing:\n",
      "-0.0998 -0.3358  0.3093  0.0339  0.4716\n",
      "[torch.cuda.FloatTensor of size 1x5 (GPU 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import multiprocessing\n",
    "from multiprocessing import Queue\n",
    "import random\n",
    "\n",
    "class TwoPathConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPathConv, self).__init__()\n",
    "        self.local_conv1 = nn.Conv3d(4, 64, (7, 7, 3))\n",
    "        self.local_conv2 = nn.Conv3d(64, 64, (3, 3, 3))\n",
    "        self.local_conv3 = nn.Conv3d(4, 160, (13, 13, 5))\n",
    "        self.total_conv = nn.Conv3d(224, 5, (21, 21, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        under_x = F.relu(self.local_conv3(x))\n",
    "        x = self.local_conv1(x)\n",
    "        x = F.max_pool3d(F.relu(x), (4, 4, 1), stride = 1)\n",
    "        x = self.local_conv2(x)\n",
    "        x = F.max_pool3d(F.relu(x), (2, 2, 1), stride = 1)\n",
    "        x = torch.cat((x, under_x), 1)\n",
    "        x = self.total_conv(x)\n",
    "        x = x.view(-1,5)\n",
    "        return x\n",
    "        \n",
    "net = TwoPathConv()\n",
    "net = net.cuda(1)\n",
    "print(net)\n",
    "\n",
    "x = Variable(torch.randn(1,4,33,33,5), requires_grad = True)\n",
    "x = x.cuda(1)\n",
    "y_pred = net.forward(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8998296\n"
     ]
    }
   ],
   "source": [
    "file_list = open('/home/yiqin/trainval-balanced.txt','r')\n",
    "f = h5py.File('/home/yiqin/train.h5','r')\n",
    "list1 = []\n",
    "str1 = file_list.readlines()\n",
    "for i in range(len(str1)):\n",
    "    list1.append(str1[i][0:-1].split(' '))\n",
    "print(len(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368998\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "input1 = open('HG0001_Val_list.pkl', 'rb')\n",
    "input2 = open('training_list.pkl', 'rb')\n",
    "val_list = pkl.load(input1)\n",
    "train_list = pkl.load(input2)\n",
    "print(len(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#without multiprocessing\n",
    "SAMPLE = [\"LG/0001\", \"LG/0002\", \"LG/0004\", \"LG/0006\", \"LG/0008\", \"LG/0011\",\n",
    "          \"LG/0012\", \"LG/0013\", \"LG/0014\", \"LG/0015\", \"HG/0001\", \"HG/0002\",\n",
    "          \"HG/0003\", \"HG/0004\", \"HG/0005\", \"HG/0006\", \"HG/0007\", \"HG/0008\",\n",
    "          \"HG/0009\", \"HG/0010\", \"HG/0011\", \"HG/0012\", \"HG/0013\", \"HG/0014\",\n",
    "          \"HG/0015\", \"HG/0022\", \"HG/0024\", \"HG/0025\", \"HG/0026\", \"HG/0027\"]\n",
    "def create_sub_patch_phase1(size, key):\n",
    "    training_patch = []\n",
    "    training_label = []\n",
    "    len_data = len(train_list)\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = train_list[key * size + i]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        content = f[case1][case2]\n",
    "        img_patch = content[:, x-16:x+16+1, y-16:y+16+1, z-2:z+3]\n",
    "        training_patch.append(img_patch)\n",
    "        training_label.append(l)\n",
    "    train_patch = torch.from_numpy(np.array(training_patch))\n",
    "    train_label = torch.from_numpy(np.array(training_label))\n",
    "    return train_patch, train_label\n",
    "\n",
    "\n",
    "def create_test_patch(img = 0, x = 16, z= 100):\n",
    "    patch=[]\n",
    "    case = SAMPLE[img]\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    batch = []\n",
    "    _, X, Y, Z = f[case1][case2].shape\n",
    "    for y in range(16, Y - 17):\n",
    "        patch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z-2:z+3])\n",
    "    patch = torch.from_numpy(np.array(patch))\n",
    "    return patch\n",
    "\n",
    "\n",
    "def create_val_patch(size):\n",
    "    val_patch = []\n",
    "    val_label = []\n",
    "    len_data = len(val_list)\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = train_list[i]\n",
    "        #print(i, key)\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        content = f[case1][case2]\n",
    "        img_patch = content[:, x-16:x+16+1, y-16:y+16+1, z-2:z+3] #sample a 33x33 patch\n",
    "        val_patch.append(img_patch)\n",
    "        val_label.append(l)\n",
    "    val_patch = torch.from_numpy(np.array(val_patch))\n",
    "    val_label = torch.from_numpy(np.array(val_label))\n",
    "    return val_patch, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 4, 33, 33, 5]) torch.Size([512])\n",
      "1.2217520000000022\n"
     ]
    }
   ],
   "source": [
    "prev_time = time.clock()\n",
    "training_patch, training_label = create_sub_patch_phase1(512, 0)\n",
    "print(training_patch.size(), training_label.size())\n",
    "print(time.clock() - prev_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 /100: \n",
      " 1.6094\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 3)]\n",
      "\n",
      "0.0 finished\n",
      "Validation accuracy: 0.20703125\n",
      "time used:19.885\n",
      "iteration 50 /100: \n",
      " 1.5036\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 3)]\n",
      "\n",
      "0.5 finished\n",
      "Validation accuracy: 0.26953125\n",
      "time used:51.839\n",
      "phase1: successfully trained!\n",
      "phase1: successfully saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prev_time = time.clock()\n",
    "num_epoch = 2\n",
    "batch_size = 256\n",
    "iteration = len(train_list) // batch_size\n",
    "net = TwoPathConv()\n",
    "net = net.cuda(3)\n",
    "\n",
    "#set hyperparams\n",
    "learning_rate = 5e-4\n",
    "l1_reg = 5e-5\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum = 0.9, weight_decay = 5e-10)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "#weight init\n",
    "for param in net.parameters():\n",
    "    ini.uniform(param, a=-5e-7, b=5e-7)\n",
    "\n",
    "#create val set\n",
    "val_patch_size = 256\n",
    "val_x, val_y = create_val_patch(val_patch_size)\n",
    "val_x, val_y = Variable(val_x.cuda(3)), val_y.cuda(3)\n",
    "\n",
    "test_X = create_test_patch(img = 10)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    random.shuffle(train_list)\n",
    "    for j in range(iteration):\n",
    "        training_patch, training_label = create_sub_patch_phase1(batch_size, j)\n",
    "        x_train, y_train = Variable(training_patch.cuda(3)), Variable(training_label.cuda(3), requires_grad=False)\n",
    "        #train\n",
    "        y_pred = net.forward(x_train)\n",
    "        y_pred = y_pred.view(-1,5)\n",
    "        loss = F.cross_entropy(y_pred, y_train)#cross entropy loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #check accuracy\n",
    "        if j%2000 == 0:\n",
    "            print('iteration %d /%d:'%(j, iteration), loss.data)\n",
    "            print(float(j)/iteration,  'finished')\n",
    "            val_pred = net.forward(val_x)\n",
    "            val_pred = val_pred.view(-1, 5)\n",
    "            _, predicted = torch.max(val_pred.data, 1)\n",
    "            correct = (predicted == val_y).sum()\n",
    "            print('Validation accuracy:', float(correct) / val_patch_size)\n",
    "            print('time used:%.3f'% (time.clock() - prev_time))\n",
    "    scheduler.step()\n",
    "    \n",
    "print (\"phase1: successfully trained!\")\n",
    "torch.save(net.state_dict(), \"/home/yiqin/phase1_TwoPathConv_net3d.txt\")\n",
    "print (\"phase1: successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23709634\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "input1 = open('training_list_unbalanced.pkl','rb')\n",
    "input2 = open('HG0001_Val_list_unbalanced.pkl', 'rb')\n",
    "train_list_unbalanced = pkl.load(input1)\n",
    "val_list_unbalanced = pkl.load(input2)\n",
    "print(len(train_list_unbalanced))\n",
    "f = h5py.File('/home/yiqin/train.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#without multiprocessing\n",
    "SAMPLE = [\"LG/0001\", \"LG/0002\", \"LG/0004\", \"LG/0006\", \"LG/0008\", \"LG/0011\",\n",
    "          \"LG/0012\", \"LG/0013\", \"LG/0014\", \"LG/0015\", \"HG/0001\", \"HG/0002\",\n",
    "          \"HG/0003\", \"HG/0004\", \"HG/0005\", \"HG/0006\", \"HG/0007\", \"HG/0008\",\n",
    "          \"HG/0009\", \"HG/0010\", \"HG/0011\", \"HG/0012\", \"HG/0013\", \"HG/0014\",\n",
    "          \"HG/0015\", \"HG/0022\", \"HG/0024\", \"HG/0025\", \"HG/0026\", \"HG/0027\"]\n",
    "def create_training_patch_phase2(size, key):\n",
    "    training_patch = []\n",
    "    training_label = []\n",
    "    len_data = len(train_list_unbalanced)\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = train_list_unbalanced[key * size + i]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        content = f[case1][case2]\n",
    "        img_patch = content[:, x-16:x+16+1, y-16:y+16+1, z-2:z+3] #sample a 33x33 patch\n",
    "        training_patch.append(img_patch)\n",
    "        training_label.append(l)\n",
    "    train_patch = torch.from_numpy(np.array(training_patch))\n",
    "    train_label = torch.from_numpy(np.array(training_label))\n",
    "    return train_patch, train_label\n",
    "\n",
    "def create_val_patch(size):\n",
    "    val_patch = []\n",
    "    val_label = []\n",
    "    len_data = len(val_list_unbalanced)\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = val_list_unbalanced[i]\n",
    "        #print(i, key)\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        content = f[case1][case2]\n",
    "        img_patch = content[:, x-16:x+16+1, y-16:y+16+1, z-2:z+3] #sample a 33x33 patch\n",
    "        val_patch.append(img_patch)\n",
    "        val_label.append(l)\n",
    "    val_patch = torch.from_numpy(np.array(val_patch))\n",
    "    val_label = torch.from_numpy(np.array(val_label))\n",
    "    return val_patch, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 2\n",
    "batch_size = 256\n",
    "iteration = len(train_list_unbalanced) // batch_size\n",
    "net = TwoPathConv()\n",
    "net.load_state_dict(torch.load('/home/yiqin/phase1_TwoPathConv_net3d.txt'))\n",
    "net = net.cuda(3)\n",
    "\n",
    "\n",
    "learning_rate = 5e-5\n",
    "l1_reg = 5e-5\n",
    "optimizer = torch.optim.SGD(net.total_conv.parameters(), lr=learning_rate, momentum = 0.9, weight_decay = 5e-10)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0234375\n"
     ]
    }
   ],
   "source": [
    "val_patch_size = 256\n",
    "val_x, val_y = create_val_patch(val_patch_size)\n",
    "print((val_y == 4).sum() *1.0 / 256)\n",
    "val_x, val_y = Variable(val_x.cuda(3)), val_y.cuda(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 /92615: \n",
      " 1.4667\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 3)]\n",
      "\n",
      "0.0 finished\n",
      "Validation accuracy: 0.5703125\n",
      "time used:1.618\n",
      "iteration 50 /92615: \n",
      " 0.9232\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 3)]\n",
      "\n",
      "0.0005398693516169087 finished\n",
      "Validation accuracy: 0.890625\n",
      "time used:27.294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-990702385c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtraining_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_training_patch_phase2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-944475fe9d3d>\u001b[0m in \u001b[0;36mcreate_training_patch_phase2\u001b[0;34m(size, key)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcase2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimg_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#sample a 33x33 patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtraining_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtraining_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_time = time.clock()\n",
    "for i in range(num_epoch):\n",
    "    for j in range(iteration):\n",
    "        training_patch, training_label = create_training_patch_phase2(batch_size, j)\n",
    "        x_train, y_train = Variable(training_patch.cuda(3)), Variable(training_label.cuda(3), requires_grad=False)\n",
    "        #train\n",
    "        y_pred = net.forward(x_train)\n",
    "        y_pred = y_pred.view(-1,5)\n",
    "        loss = F.cross_entropy(y_pred, y_train)#cross entropy loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #check accuracy\n",
    "        if j%2000 == 0:\n",
    "            print('iteration %d /%d:'%(j, iteration), loss.data)\n",
    "            print(float(j)/iteration,  'finished')\n",
    "            val_pred = net.forward(val_x)\n",
    "            val_pred = val_pred.view(-1, 5)\n",
    "            _, predicted = torch.max(val_pred.data, 1)\n",
    "            correct = (predicted == val_y).sum()\n",
    "            print('Validation accuracy:', float(correct) / val_patch_size)\n",
    "            print('time used:%.3f'% (time.clock() - prev_time))\n",
    "    scheduler.step()\n",
    "print (\"phase2: successfully trained!\")\n",
    "torch.save(net.state_dict(), \"/home/yiqin/phase2_TwoPathConv_net3d.txt\")\n",
    "print (\"phase2: successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
